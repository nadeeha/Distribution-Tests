import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import re

# Define the ETF DataFrames (assuming they are already loaded)
etf_dfs = {
    "XAIX_GT": df_xaixgt_rbics,  # AI & Big Data
    "LOCK_LN": df_lockln_rbics,  # Digital Security
    "SMH_LN": df_smhl_rbics,  # Semiconductors
    "IXAROBU": df_ixarobu_rbics,  # Robotics
    "IXDIGITU": df_ixdigitu_rbics  # Digital Transformation
}

# Expected categories per ETF
# ğŸš€ Updated Expected Keywords for Each ETF
expected_rbics = {
    "XAIX_GT": [  # AI & Big Data
        "ai", "artificial intelligence", "machine learning", "deep learning", "neural networks",
        "computer vision", "nlp", "natural language processing", "predictive analytics", 
        "data science", "ai-powered", "automated", "automation", "cognitive",
        "reinforcement", "speech", "image", "recognition", "analytics", "prediction",
        "intelligent", "algorithm", "adaptive", "autonomous", "chatbot"
    ],
    
    "LOCK_LN": [  # Cybersecurity & Digital Security
        "cybersecurity", "security", "network", "threat", "encryption", "firewall",
        "penetration", "malware", "privacy", "access", "secure", "zero trust", 
        "endpoint", "digital", "identity", "protection", "vpn", "intrusion", "phishing",
        "blockchain", "compliance", "auth", "ransomware", "breach"
    ],
    
    "SMH_LN": [  # Semiconductors & Hardware
        "semiconductor", "chip", "processor", "memory", "integrated", "circuits",
        "gpu", "cpu", "microcontroller", "embedded", "transistor", "quantum",
        "fabrication", "wafer", "nanotechnology", "foundry", "logic", "power",
        "optoelectronics", "hardware", "system-on-chip", "microchip", "silicon",
        "electronic", "module", "ic", "component", "design"
    ],
    
    "IXAROBU": [  # Robotics & Automation
        "robot", "automation", "industrial", "rpa", "drones", "autonomous", "ai robotics",
        "navigation", "exoskeleton", "warehouse", "robotic", "sensors", "self-driving",
        "welding", "assembly", "humanoid", "cobot", "collaborative", "manipulation",
        "bipedal", "drone", "automation", "automated", "motion", "vision"
    ],
    
    "IXDIGITU": [  # Digital Transformation & Emerging Tech
        "digital", "cloud", "enterprise", "blockchain", "decentralized", "distributed",
        "iot", "internet", "5g", "wireless", "fiber", "edge", "metaverse",
        "augmented", "virtual", "mixed", "saas", "paas", "twins", "computational",
        "software", "cloud-native", "hybrid", "infrastructure", "virtualization",
        "protocol", "automation", "computing", "server", "storage", "networks"
    ]
}
# List of RBICS levels and their descriptions
rbics_levels = ["l3_name", "l4_name", "l5_name", "l6_name"]
rbics_descriptions = ["l3_description", "l4_description", "l5_description", "l6_description"]

# Store results
summary_list = []
all_holdings_count = []
all_sector_proportion = []
all_non_relevant_holdings = []

# Function to check exact word match in RBICS categories/descriptions
def exact_match(text, keywords):
    words = re.split(r'\W+', str(text).lower())  # Split into words, remove punctuation
    return any(word in words for word in keywords)

### ğŸŸ¢ Process Each ETF Separately ###
for etf_name, df in etf_dfs.items():
    print(f"Processing {etf_name}...")

    # Ensure weight column is numeric
    df['weight'] = pd.to_numeric(df['weight'], errors='coerce')

    # Convert all RBICS levels and descriptions to lowercase for uniformity
    for level, description in zip(rbics_levels, rbics_descriptions):
        df[level] = df[level].astype(str).str.lower()
        df[description] = df[description].astype(str).str.lower()

    # Define expected keywords for this ETF
    expected_keywords = expected_rbics[etf_name]
    expected_keywords = [word.lower() for word in expected_keywords]

    # Apply keyword matching row-wise
    df['row_match'] = df.apply(lambda row: 
        exact_match(row['l3_name'], expected_keywords) or
        exact_match(row['l4_name'], expected_keywords) or
        exact_match(row['l5_name'], expected_keywords) or
        exact_match(row['l6_name'], expected_keywords) or
        exact_match(row['l3_description'], expected_keywords) or
        exact_match(row['l4_description'], expected_keywords) or
        exact_match(row['l5_description'], expected_keywords) or
        exact_match(row['l6_description'], expected_keywords), axis=1)

    # Aggregate results at the ISIN level (if any row for ISIN matches, mark entire ISIN as relevant)
    isin_match = df.groupby('ISIN')['row_match'].max().reset_index()
    isin_match.rename(columns={'row_match': 'matches_etf_category'}, inplace=True)

    # Merge aggregated match results back to original dataframe
    df = df.merge(isin_match, on='ISIN', how='left')

    # Flag non-relevant holdings
    non_relevant_holdings = df[df['matches_etf_category'] == False].copy()
    non_relevant_holdings['ETF'] = etf_name
    all_non_relevant_holdings.append(non_relevant_holdings)

    ### 4ï¸âƒ£ Generate Summary Statistics ###
    total_holdings = df['ISIN'].nunique()  # Unique ISINs
    relevant_match_count = isin_match['matches_etf_category'].sum()
    non_relevant_count = total_holdings - relevant_match_count
    total_weight = df['weight'].sum()
    relevant_match_pct = (relevant_match_count / total_holdings) * 100 if total_holdings > 0 else 0

    summary_list.append({
        "ETF": etf_name,
        "Total Unique ISINs": total_holdings,
        "Relevant Match Count": relevant_match_count,
        "Non-Relevant Count": non_relevant_count,
        "Relevant Match Percentage": relevant_match_pct,
        "Total Weight": total_weight
    })

### ğŸŸ¢ Convert Results into DataFrames ###
summary_df = pd.DataFrame(summary_list)
non_relevant_holdings_df = pd.concat(all_non_relevant_holdings, ignore_index=True)

### ğŸŸ¢ 5. Generate Visualizations ###

# ğŸ“Š Bar Chart: Number of Holdings per RBICS Level for Each ETF
plt.figure(figsize=(12, 6))
sns.barplot(data=summary_df, x='ETF', y='Relevant Match Percentage')
plt.xticks(rotation=90)
plt.ylabel("Relevant Match Percentage (%)")
plt.title("Percentage of Relevant Holdings in Each ETF")
plt.show()

# ğŸ“Š Stacked Bar Chart: Sector Proportions per ETF
plt.figure(figsize=(12, 6))
pivot_data = summary_df.set_index("ETF")[["Relevant Match Count", "Non-Relevant Count"]]
pivot_data.plot(kind='bar', stacked=True, figsize=(12, 6))
plt.xticks(rotation=90)
plt.ylabel("Number of Holdings")
plt.title("Relevant vs. Non-Relevant Holdings in ETFs")
plt.legend(title="Holdings Classification")
plt.show()

### ğŸŸ¢ 6. Save Results to CSV ###
summary_df.to_csv("summary_etf_analysis.csv", index=False)
non_relevant_holdings_df.to_csv("non_relevant_holdings.csv", index=False)

# Print Summary
print("\nğŸ” Summary of ETF Analysis:")
print(summary_df)
