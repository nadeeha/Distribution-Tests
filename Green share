Here's a clear and structured flow for your presentation slide with step-wise write-ups. This will help narrate the journey from raw FactSet revenue data to thematic tagging and green share calculation using GenAI and taxonomy mapping:


---

Slide Title: From FactSet Revenue Data to Thematic Green Share Tagging


---

Step 1: FactSet Revenue Data (L1 to L6)

Input: Structured revenue segmentation from FactSet at multiple levels (L1 → L6).

Purpose: Provides granular business activity data for ~40,000+ companies.

Example:

L1: Industrials

L6: Waste Recycling Services




---

Step 2: Master File Creation — Inclusion/Exclusion Decision

Objective: Classify L6 revenue items as “Include” or “Exclude” for green tagging.

Basis of Decision:

ESG frameworks (e.g., EU Taxonomy, GFANZ)

Thematic reference documents (e.g., Ellen MacArthur Foundation for Circular Economy)

Existing off-the-shelf mappings from data providers or domain experts.


Themes Considered:

Circular Economy

Climate Adaptation

Climate Mitigation




---

Step 3: Thematic Taxonomy Development

Process:

Build multi-level taxonomies for each theme (e.g., Circular Economy → Material Efficiency → Recycling).

Structure the taxonomy with L1 → L2 → L3 layers (not all branches may have L3).


Source: Human + AI-assisted curation using policy papers, frameworks, and GenAI insights.



---

Step 4: GenAI-Assisted Mapping (Taxonomy → L6 Revenue Items)

Tool: GPT-4 or domain-tuned LLMs

Function: Map each L6 to relevant taxonomy paths for each theme based on semantic understanding.

Outcome: Every L6 (if “included”) is assigned a hierarchical tag (e.g., Circular Economy > Recycling > Industrial Waste).



---

Step 5: Tagging Companies Using FactSet Revenue Data

Action: Match L6s from the master file to each company’s revenue profile.

If L6 is “Include”:

Tag it to the correct theme and hierarchy path.

Use this for green share calculation — % of revenue from green-aligned activities.




---

Step 6: Green Share Calculation

Formula:


\text{Green Share} = \frac{\sum \text{Revenue from Included L6s}}{\sum \text{Total Revenue}}


---

Step 7: Biodiversity Theme (Ongoing Work by Group Ventures & Innovation)

Status: Early-stage — Limited public documentation

Challenge: Lack of structured external frameworks to anchor inclusion/exclusion decisions.

Approach: Collaborative research, possibly domain-expert interviews, and exploratory GenAI applications.



---

Optional Visual:

Use a flowchart with vertical swimlanes:

1. Data Input (FactSet L1–L6)


2. Filtering (Master File Inclusion/Exclusion)


3. Taxonomy Creation


4. AI Mapping (L6 → Themes)


5. Company Tagging


6. Green Share Output




Would you like me to generate this flow as a diagram or slide visual?

________

Here’s a structured slide flow and write-up for “Validation of Economic Activity Clusters for Biodiversity” that aligns with your narrative:


---

Slide Title: Validating Biodiversity Economic Activity Clusters using GenAI


---

Step 1: Initial Extraction by Group Ventures & Innovation

Input: ESG/Science/Policy documents related to biodiversity.

Output: Over 10,000 unique economic activities extracted for potential biodiversity relevance.

Challenge: Too voluminous for manual SME (Subject Matter Expert) review.



---

Step 2: Clustering for Manageability

Action: Grouped 10,000+ economic activities into ~400 semantic clusters of similar activities using NLP techniques or vector-based similarity.

Objective: Make SME validation more feasible.

Challenge: Still too large and complex for exhaustive human evaluation.



---

Step 3: GenAI-Based Cluster Validation

Tool: GPT-4 or fine-tuned LLMs guided by domain-specific prompts.

Validation Criteria:

Impact Type: What kind of biodiversity impact is associated? (e.g., positive, neutral, negative)

Confidence Level: How certain is the model about this impact? (e.g., High/Medium/Low)

Preferred Label: A concise, human-readable label for the cluster

Suggested Alternative Label: If preferred label is ambiguous or misleading




---

Step 4: Shortlisting and Mapping

Outcome: GenAI-validated shortlist of high-confidence clusters with:

Clear biodiversity relevance

Suitable for SME review

Mapped to FactSet L6 revenue segments where possible




---

Key Benefits of GenAI in This Process

Scalability: Reduced manual effort significantly

Explainability: Generated rationales for impact type and label choices

Efficiency: Prioritized meaningful clusters for deeper human validation



---

Optional Visual:

Funnel Diagram or Layered Box Flowchart:

Box 1: 10K+ Economic Activities →

Box 2: ~400 Clusters (Semantic Grouping) →

Box 3: GenAI Review (Impact Type, Confidence, Labels) →

Box 4: Final Validated Clusters →

Box 5: Mapping to FactSet L6



Would you like a slide or visual generated for this too?



__________

Here’s a clean and structured flow + write-up for your next slide on automating information extraction from reports using GenAI (API-based approach):


---

Slide Title: Automating ESG Report Information Retrieval with GenAI APIs


---

Context:

Manual Effort Limitation: A sample extraction was previously done using a UI-based GenAI tool.

Objective: Test a scalable, API-driven approach to extract key insights across multiple sustainability reports.



---

Step-by-Step Process: API-Based Extraction Pipeline

1. Input Collection

Documents: Company ESG or sustainability reports (PDFs)

Task: Extract specific KPIs (e.g., renewable energy use, green steel %)



---

2. Preprocessing

Page Parsing: Extract text and page numbers from each PDF

Chunking: Use RecursiveCharacterTextSplitter to break long text into overlapping, meaningful chunks for embedding



---

3. Embedding Creation

Model: MiniLM (Lightweight transformer model)

Output: Embeddings + metadata (e.g., page number, source)

Storage: Built a FAISS Vector Store to enable fast similarity search



---

4. Query and Retrieval

Query Input: Human-defined or pre-coded prompt (e.g., "What is the % of green steel produced?")

Similarity Search: Retrieve top-N relevant chunks from the FAISS store

LLM Answering: Send query + top chunks to GPT-4o mini via API



---

5. Output Storage

Result: Structured output with:

Answer

Confidence (optional)

Source page


Final Storage: Compiled into an Excel sheet for downstream analysis



---

Why This Approach Works

Scalable: Works on 10s–100s of reports without UI/manual input

Transparent: Traceable page-level outputs

Efficient: Faster than fully manual GenAI UI workflows



---

Optional Visual Suggestion:

Use a horizontal pipeline diagram with these labeled blocks:

> PDF Reports → Page Extractor → Chunking → MiniLM Embedding → FAISS Index → GPT-4o Retrieval → Excel Output



Would you like this turned into a diagram or slide visual too?


